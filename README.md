Репозиторий kafka-flink-streaming - проект по предмету "Потоковый анализ данных".
За основу этого проекта взят репозиторий [flink_sql_job](https://github.com/platykurtic-icu/flink_sql_job/tree/main?tab=readme-ov-file).

**Лабораторная №1**

Предметная область — электронная коммерция, в частности — система анализа продаж в реальном времени. Система строится на базе генерации событий о продажах и последующей потоковой обработки этих данных для извлечения аналитики.

1. Потоковые данные
Потоковыми данными в этой области являются:
 - Транзакции (события покупки): информация о товарах, количестве, стоимости, пользователе, времени и месте продажи.
 - События взаимодействия пользователей: добавление товара в корзину, просмотр, клики.
 - Метаданные по продуктам, каналам продаж и т. д.
Источник данных — Kafka-продюсер, реализованный в репозитории [kafka_sales_producer](https://github.com/platykurtic-icu/kafka_sales_producer/tree/main). Он генерирует поток транзакций в Kafka-топик sales.

2. Ожидаемые результаты обработки
В результате потоковой обработки можно получить:
 - Агрегации: общая сумма продаж, средний чек, количество продаж по категориям.
 - Аномалии: всплески активности или подозрительные транзакции.
 - Топ-товары: товары-лидеры по продажам за промежуток времени.
 - Динамика: временные ряды продаж (по минутам, часам, дням).
В самом проекте был реализован подсчет общего кол-ва продаж в разрезе магазина в интервалах одной минуты.
Данные агрегации записываются в Kafka-топик sales_aggregate.

3. Потенциальная роль машинного обучения
Машинное обучение может быть задействовано в следующих задачах:
 - Фрод-детекция: выявление подозрительных покупок (например, по геолокации или частоте).
 - Прогнозирование спроса: предсказание объема продаж по продуктам.
 - Рекомендательные системы: персонализация на основе поведения в реальном времени.

4. Требования к задержке обработки
Задержка критична:
 - Система должна обрабатывать данные в режиме реального времени или почти в реальном времени (низкая латентность).
 - Максимально допустимая задержка — 1-2 секунды, иначе данные теряют актуальность.
Потенциальный пример - OZON, у которого всегда под рукой должны быть live данные о продажах, потому что это может влиять на персонализацию, своевременную реакцию на кол-во доступного товара и тд. 

5. Отношение к потере данных
Потеря данных недопустима:
 - Каждая транзакция должна быть обработана ровно один раз (семантика exactly once).
 - Потеря данных приведёт к искажению метрик и финансовым рискам.

7. Источник данных
Для генерации потоков синтетических сообщений используется сервис my_producer, который обращается к [kafka_sales_producer/src/main/java/com/acosom/App.java](https://github.com/platykurtic-icu/kafka_sales_producer/blob/main/src/main/java/com/acosom/App.java):
kafka_sales_producer генерирует транзакции и публикует их в Kafka-топик sales.
Дальнейшая обработка реализуется в Apache Flink c помощью SQL-клиента:
 - Запускается Flink SQL Client.
 - Он подключается к кластеру Flink и Kafka, и через SQL-файл регистрирует стриминговую обработку данных.
 - Эта обработка запускается как постоянно работающий Flink Job, который читает SALES, агрегирует, и пишет в SALES_AGGREGATE.
